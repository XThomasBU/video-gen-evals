<!DOCTYPE html>
<html>
  <script>
    window.MathJax = {
      tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
      svg: { fontCache: 'global' }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>
<head>
  <meta charset="utf-8">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="https://cdn.plot.ly/plotly-2.26.0.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero" style="padding-top: 2rem; padding-bottom: 0.5rem; animation: fadeInUp 0.8s ease-out;">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title" style="font-weight: 700; letter-spacing: -0.02em; margin-bottom: 1.5rem;">
              Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos
            </h1>
            <!-- <div class="is-size-5 has-text-centered" style="margin-bottom: 1rem;">
              <strong>ICCV 2025</strong>
            </div> -->
            <div class="is-size-5 publication-authors" style="font-weight: 300; letter-spacing: 0.01em; line-height: 1.8;">
              <span class="author-block"><a href="https://xavierohan.github.io" style="color: inherit; text-decoration: none;">Xavier Thomas</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://sgt-lim.github.io" style="color: inherit; text-decoration: none;">Youngsun Lim</a><sup>1</sup>,</span>
              <span class="author-block"><a href="http://www.linkedin.com/in/ananya-srinivasann" style="color: inherit; text-decoration: none;">Ananya Srinivasan</a><sup>2</sup><sup>*</sup>,</span>
              <span class="author-block"><a href="https://www.linkedin.com/in/audrey-zheng-6443b5314/" style="color: inherit; text-decoration: none;">Audrey Zheng</a><sup>3</sup><sup>*</sup>,</span>
              <span class="author-block"><a href="https://deeptigp.github.io" style="color: inherit; text-decoration: none;">Deepti Ghadiyaram</a><sup>1,4</sup></span>
            </div>

            <div class="is-size-6 publication-authors" style="margin-top: 0.75rem; font-weight: 300; color: #666; letter-spacing: 0.01em;">
              <span class="author-block">
                <sup>1</sup>Boston University,
                <sup>2</sup>Belmont High School,
                <sup>3</sup>Canyon Crest Academy,
                <sup>4</sup>Runway
              </span>
            </div>

            <div class="is-size-6" style="margin-top: 0.4rem; font-weight: 300; color: #666; letter-spacing: 0.01em;">
              <span class="author-block"><sup>*</sup>Equal contribution</span>
            </div>

  
  
            <div class="column has-text-centered" style="margin-top: 2rem;">
              <div class="publication-links">
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2512.01803" target="_blank"
                    class="external-link button is-normal is-rounded" style="background: transparent; border: 1px solid #ddd; color: #333; font-weight: 300; letter-spacing: 0.02em;">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
  
                <!-- Github link -->
                <span class="link-block">
                  <a href="" target="_blank"
                    class="external-link button is-normal is-rounded" style="background: transparent; border: 1px solid #ddd; color: #333; font-weight: 300; letter-spacing: 0.02em;">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (coming soon)</span>
                  </a>
                </span>
  
                <!-- Data link -->
                <span class="link-block">
                  <a href="" target="_blank"
                    class="external-link button is-normal is-rounded" style="background: transparent; border: 1px solid #ddd; color: #333; font-weight: 300; letter-spacing: 0.02em;">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>Data (TAG-Bench) (Coming soon)</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

<!-- Hero divider -->
<div class="hero-divider"></div>

<!-- Video container -->
<section class="section" style="padding-top: 0.5rem; padding-bottom: 3rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <p style="font-size: 0.85rem; color: #888; font-weight: 300; margin-bottom: 1rem; letter-spacing: 0.02em;">A short silent video designed to supplement the paper</p>
        <div class="video-container" style="position: relative; width: 100%; padding-bottom: 56.25%; height: 0; overflow: hidden;">
          <video 
            muted 
            loop 
            playsinline
            controls
            preload="auto"
            style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover;"
          >
            <source src="static/videos/Generative Action Tell-Tales_ Assessing Human Motion in Synthesized Videos.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video container -->

<!-- Section divider -->
<div class="section-divider"></div>

<!-- Paper abstract -->
<section class="section" style="padding-top: 4rem; padding-bottom: 4rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4" style="font-weight: 700; letter-spacing: -0.01em; margin-bottom: 1.5rem;">Abstract</h2>
        <div class="content has-text-justified" style="font-size: 1rem; line-height: 1.75; font-weight: 300; color: #333;">
          <p>
            Despite rapid advances in video generative models, robust metrics for evaluating visual and temporal correctness of complex human actions remain elusive. Critically, existing pure-vision encoders and Multimodal Large Language Models (MLLMs) are strongly appearance-biased, lack temporal understanding, and thus struggle to discern intricate motion dynamics and anatomical implausibilities in generated videos. We tackle this gap by introducing a novel evaluation metric derived from a learned latent space of real-world human actions. Our method first captures the nuances, constraints, and temporal smoothness of real-world motion by fusing appearance-agnostic human skeletal geometry features with appearance-based features. We posit that this combined feature space provides a robust representation of action plausibility. Given a generated video, our metric quantifies its action quality by measuring the distance between its underlying representations to this learned real-world action distribution. For rigorous validation, we develop a new multi-faceted benchmark specifically designed to probe temporally challenging aspects of human action fidelity. Through extensive experiments, we demonstrate that our metric achieves substantial improvement of over 68% over existing state-of-the-art methods on our benchmark, performs competitively on established external benchmarks, and has a stronger correlation with human perception. Our in-depth analysis reveals critical limitations in current video generative models and establishes a new standard for advanced research in video generation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Section divider -->
<div class="section-divider"></div>

<!-- Section 1: Current metrics fail -->
<section class="section" style="padding-top: 3rem; padding-bottom: 3rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4" style="font-weight: 700; letter-spacing: -0.01em; margin-bottom: 1.5rem; color: #333;">
          Current automatic video metrics and MLLMs struggle to evaluate human motion in generated videos
        </h2>
      </div>
    </div>
  </div>
</section>
<!-- End section 1 -->

<!-- Section divider -->
<div class="section-divider"></div>

<!-- Section 2: Key Idea -->
<section class="section" style="padding-top: 3rem; padding-bottom: 3rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4" style="font-weight: 700; letter-spacing: -0.01em; margin-bottom: 1.5rem; color: #333;">
          <strong>Key idea</strong>: Judge realism by looking at how <strong>real humans</strong> perform an action
        </h2>
        <div style="margin-top: 2rem;">
          <img src="static/images/hero.pdf" alt="Key Idea visualization" style="width: 110%; height: auto; margin-left: -5%; border-radius: 2px; image-rendering: -webkit-optimize-contrast; transform: translateZ(0); -webkit-backface-visibility: hidden; backface-visibility: hidden;" />
        </div>
        
        <h2 class="title is-4" style="font-weight: 700; letter-spacing: -0.01em; margin-top: 4rem; margin-bottom: 1.5rem; color: #333;">
          Break human motion down to its <strong>intrinsics</strong>
        </h2>
        <div style="margin-top: 2rem; margin-bottom: 5rem;">
          <img src="static/images/Temp-pages-intrinsics-2.pdf" alt="Break human motion down to its intrinsics" style="width: 110%; height: auto; margin-left: -5%; border-radius: 2px; image-rendering: -webkit-optimize-contrast; transform: translateZ(0); -webkit-backface-visibility: hidden; backface-visibility: hidden;" />
        </div>
        
        <h2 class="title is-4" style="font-weight: 700; letter-spacing: -0.01em; margin-top: 4.5rem; margin-bottom: 1.5rem; color: #333;">
          Use these <strong>ingredients</strong> to <strong>learn what constitutes an action</strong>
        </h2>
        <div style="margin-top: 2rem;">
          <img src="static/images/Temp-pages-encoder-2.pdf" alt="Encoder visualization" style="width: 110%; height: auto; margin-left: -5%; border-radius: 2px; image-rendering: -webkit-optimize-contrast; transform: translateZ(0); -webkit-backface-visibility: hidden; backface-visibility: hidden;" />
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End section 2 -->

<!-- Section divider -->
<div class="section-divider"></div>

<!-- Section 3: TAG-Bench -->
<section class="section" style="padding-top: 3rem; padding-bottom: 3rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4" style="font-weight: 700; letter-spacing: -0.01em; margin-bottom: 3rem; color: #333; text-align: center;">
          Telltale Action Generation Bench (TAG-Bench)
        </h2>
        
        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 4rem; margin-bottom: 4rem;">
          <!-- Generative Models -->
          <div>
            <h3 style="font-weight: 700; font-size: 1.1rem; letter-spacing: -0.01em; margin-bottom: 1.5rem; color: #333; border-bottom: 1px solid #e0e0e0; padding-bottom: 0.5rem;">
              5 Generative Models
            </h3>
            <p style="color: #555; font-weight: 300; letter-spacing: 0.01em; margin: 0; line-height: 1.6;">
              Runway Gen4, Wan2.1, Wan2.2, Opensora, HunyuanVideo
            </p>
          </div>
          
          <!-- Actions -->
          <div>
            <h3 style="font-weight: 700; font-size: 1.1rem; letter-spacing: -0.01em; margin-bottom: 1.5rem; color: #333; border-bottom: 1px solid #e0e0e0; padding-bottom: 0.5rem;">
              10 Actions
            </h3>
            <p style="color: #555; font-weight: 300; letter-spacing: 0.01em; margin: 0; line-height: 1.6;">
              Squats, Hulahoop, Jumping jack, Pull ups, Push ups, Shot put, Soccer juggling, Tennis swing, Discus throw, Wall push up
            </p>
          </div>
        </div>
        
        <!-- Human Evaluation -->
        <div style="margin-top: 3rem; padding-top: 2rem; border-top: 1px solid #e0e0e0;">
          <h3 style="font-weight: 700; font-size: 1.1rem; letter-spacing: -0.01em; margin-bottom: 2rem; color: #333; text-align: center;">
            Humans evaluate each video on:
          </h3>
          <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 3rem;">
            <div>
              <h4 style="font-weight: 700; font-size: 1rem; margin-bottom: 0.75rem; color: #333;">
                Action Consistency (1-10)
              </h4>
              <p style="color: #666; font-weight: 300; line-height: 1.6; letter-spacing: 0.01em; margin: 0;">
                How accurately the generated video depicts the intended action mentioned in the prompt.
              </p>
            </div>
            <div>
              <h4 style="font-weight: 700; font-size: 1rem; margin-bottom: 0.75rem; color: #333;">
                Temporal Coherence (1-10)
              </h4>
              <p style="color: #666; font-weight: 300; line-height: 1.6; letter-spacing: 0.01em; margin: 0;">
                How physically plausible and temporally smooth the human motion appears in the generated video.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End section 3 -->

<!-- Section divider -->
<div class="section-divider"></div>

<!-- Metrics section -->
<section class="section" style="padding-top: 3rem; padding-bottom: 3rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4" style="font-weight: 700; letter-spacing: -0.01em; margin-bottom: 1.5rem; color: #333;">
          Metrics
        </h2>
        <div style="margin-top: 2rem;">
          <img src="static/images/Temp-metrics.pdf" alt="Metrics visualization" style="width: 110%; height: auto; margin-left: -5%; border-radius: 2px; image-rendering: -webkit-optimize-contrast; transform: translateZ(0); -webkit-backface-visibility: hidden; backface-visibility: hidden;" />
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Metrics section -->

<!-- Section divider -->
<div class="section-divider"></div>

<!-- Results section -->
<section class="section" style="padding-top: 3rem; padding-bottom: 3rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4" style="font-weight: 700; letter-spacing: -0.01em; margin-bottom: 1.5rem; color: #333;">
          Results
        </h2>
        <div style="margin-top: 2rem;">
          <img src="static/images/barplot_action_consistency.pdf" alt="Action consistency barplot" style="width: 110%; height: auto; margin-left: -5%; border-radius: 2px; image-rendering: -webkit-optimize-contrast; transform: translateZ(0); -webkit-backface-visibility: hidden; backface-visibility: hidden; margin-bottom: 2.5rem;" />
          <img src="static/images/barplot_temporal_coherence.pdf" alt="Temporal coherence barplot" style="width: 110%; height: auto; margin-left: -5%; border-radius: 2px; image-rendering: -webkit-optimize-contrast; transform: translateZ(0); -webkit-backface-visibility: hidden; backface-visibility: hidden; margin-bottom: 2.5rem;" />
          
          <h3 style="font-weight: 600; font-size: 1.2rem; letter-spacing: -0.01em; margin-bottom: 2rem; margin-top: 3rem; color: #333; text-align: center;">
            Overall model performance (win ratios)
          </h3>
          <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 2rem; margin-bottom: 2.5rem;">
            <div>
              <img src="static/images/vbench_cons.pdf" alt="Action Consistency" style="width: 110%; height: auto; margin-left: -5%; border-radius: 2px; image-rendering: -webkit-optimize-contrast; transform: translateZ(0); -webkit-backface-visibility: hidden; backface-visibility: hidden; margin-bottom: 0.75rem;" />
              <p style="text-align: center; color: #666; font-weight: 400; font-size: 0.95rem; margin: 0;">Action Consistency</p>
            </div>
            <div>
              <img src="static/images/vbench_temp.pdf" alt="Temporal Coherence" style="width: 110%; height: auto; margin-left: -5%; border-radius: 2px; image-rendering: -webkit-optimize-contrast; transform: translateZ(0); -webkit-backface-visibility: hidden; backface-visibility: hidden; margin-bottom: 0.75rem;" />
              <p style="text-align: center; color: #666; font-weight: 400; font-size: 0.95rem; margin: 0;">Temporal Coherence</p>
            </div>
          </div>
          
          <h3 style="font-weight: 600; font-size: 1.2rem; letter-spacing: -0.01em; margin-bottom: 2rem; margin-top: 3rem; color: #333; text-align: center;">Are some actions universally easy / hard to generate?</h3>
          <div id="tsne-plot" style="width: 110%; margin-left: -5%; position: relative; min-height: 700px;"></div>
          <p style="color: #6D5BBD; text-align: center; margin-top: 1rem; font-size: 0.95rem;">Push-ups is relatively easy for all models<br>(generated video embeddings lie close to the centroid of real video embeddings)</p>
          <p style="color: #AA7942; text-align: center; margin-top: 0.5rem; font-size: 0.95rem;">Shot put is hard<br>(generated video embeddings lie far away from the centroid of real video embeddings)</p>
          
          <h3 style="font-weight: 600; font-size: 1.2rem; letter-spacing: -0.01em; margin-bottom: 2rem; margin-top: 4rem; color: #333; text-align: center;">Are all input features required?</h3>
          <div style="display: flex; justify-content: center; margin-top: 2rem; margin-bottom: 2rem;">
            <div id="ablation-interactive" style="max-width: 600px; width: 100%;">
              <!-- Feature selection -->
              <div style="margin-bottom: 2rem;">
                <div style="font-weight: 300; color: #666; font-size: 0.95rem; margin-bottom: 1rem; text-align: center;">Click features to remove them</div>
                <div id="feature-list" style="display: flex; flex-wrap: wrap; gap: 0.75rem; justify-content: center;">
                  <!-- Features will be populated by JavaScript -->
                </div>
              </div>
              
              <!-- Results display -->
              <div id="ablation-results" style="text-align: center; padding: 2rem; background: rgba(0,0,0,0.02); border-radius: 12px; transition: all 0.3s ease;">
                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 2rem;">
                  <div>
                    <div style="font-size: 0.85rem; color: #666; margin-bottom: 0.5rem; font-weight: 300;">Action Consistency</div>
                    <div id="score-consistency" style="font-size: 2rem; font-weight: 700; color: #333; letter-spacing: -0.02em;">0.61</div>
                    <div id="drop-consistency" style="font-size: 0.85rem; color: #999; margin-top: 0.25rem; font-weight: 300;"></div>
                  </div>
                  <div>
                    <div style="font-size: 0.85rem; color: #666; margin-bottom: 0.5rem; font-weight: 300;">Temporal Coherence</div>
                    <div id="score-coherence" style="font-size: 2rem; font-weight: 700; color: #333; letter-spacing: -0.02em;">0.64</div>
                    <div id="drop-coherence" style="font-size: 0.85rem; color: #999; margin-top: 0.25rem; font-weight: 300;"></div>
                  </div>
                </div>
              </div>
            </div>
          </div>
          <p style="text-align: center; margin-top: 1.5rem; font-size: 0.9rem; color: #666; line-height: 1.6; max-width: 800px; margin-left: auto; margin-right: auto; font-weight: 300; letter-spacing: 0.01em;">
            <strong style="font-weight: 700; color: #333;">Effect of each input feature.</strong> We report Spearman's correlation (œÅ) with human scores after zeroing each input feature independently. Models are retrained from scratch for each setting. "Motion" denotes temporal derivatives of all inputs. Removing motion causes the largest degradation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Results section -->

<!-- Section divider -->
<div class="section-divider"></div>

<!-- Citation section -->
<section class="section" style="padding-top: 3rem; padding-bottom: 3rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4" style="font-weight: 700; letter-spacing: -0.01em; margin-bottom: 1.5rem; color: #333; text-align: center;">
          Citation
        </h2>
        <div style="background: rgba(0,0,0,0.02); border-radius: 8px; padding: 1.5rem; margin-top: 1.5rem; position: relative;">
          <button id="copy-citation-btn" style="position: absolute; top: 1rem; right: 1rem; padding: 0.4rem 0.8rem; background: white; border: 1px solid rgba(0,0,0,0.15); border-radius: 4px; cursor: pointer; font-family: 'Noto Sans', sans-serif; font-weight: 300; font-size: 0.85rem; color: #333; letter-spacing: 0.01em; transition: all 0.2s ease;" onmouseover="this.style.background='rgba(0,0,0,0.02)'" onmouseout="this.style.background='white'">
            Copy
          </button>
          <pre id="citation-text" style="font-family: 'Noto Sans', sans-serif; font-size: 0.85rem; line-height: 1.6; color: #333; margin: 0; padding-right: 4rem; white-space: pre-wrap; word-wrap: break-word; font-weight: 300; letter-spacing: 0.01em;">@misc{thomas2025generativeactiontelltalesassessing,
      title={Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos}, 
      author={Xavier Thomas and Youngsun Lim and Ananya Srinivasan and Audrey Zheng and Deepti Ghadiyaram},
      year={2025},
      eprint={2512.01803},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.01803}, 
}</pre>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Citation section -->

<!-- Section divider -->
<div class="section-divider"></div>

<!-- References section -->
<section class="section" style="padding-top: 3rem; padding-bottom: 4rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-5" style="font-weight: 700; letter-spacing: -0.01em; margin-bottom: 2rem; color: #333; text-align: center;">
          References
        </h2>
        <div style="font-size: 0.9rem; line-height: 1.8; color: #555; font-weight: 300;">
          <p style="margin-bottom: 1.25rem;">
            <strong>RunwayGen4:</strong> Runway Research Team. Runway gen-4: Advancing realistic text-to-video generation. Technical Report, 2024. <a href="https://research.runwayml.com/gen4" target="_blank" style="color: #0066cc; text-decoration: none;">https://research.runwayml.com/gen4</a>.
          </p>
          <p style="margin-bottom: 1.25rem;">
            <strong>Wan2.1:</strong> Team Wan, Ang Wang, Baole Ai, Bin Wen, Chaojie Mao, Chen-Wei Xie, Di Chen, Feiwu Yu, Haiming Zhao, Jianxiao Yang, et al. Wan: Open and advanced large-scale video generative models. arXiv preprint arXiv:2503.20314, 2025. <a href="https://arxiv.org/abs/2503.20314" target="_blank" style="color: #0066cc; text-decoration: none;">arXiv:2503.20314</a>.
          </p>
          <p style="margin-bottom: 1.25rem;">
            <strong>Wan2.2:</strong> Team Wan, Ang Wang, Baole Ai, Bin Wen, Chaojie Mao, Chen-Wei Xie, Di Chen, Feiwu Yu, Haiming Zhao, Jianxiao Yang, et al. Wan: Open and advanced large-scale video generative models. arXiv preprint arXiv:2503.20314, 2025. <a href="https://arxiv.org/abs/2503.20314" target="_blank" style="color: #0066cc; text-decoration: none;">arXiv:2503.20314</a>.
          </p>
          <p style="margin-bottom: 1.25rem;">
            <strong>Hunyuan:</strong> Weijie Kong, Qi Tian, Zijian Zhang, Rox Min, Zuozhuo Dai, Jin Zhou, Jiangfeng Xiong, Xin Li, Bo Wu, Jianwei Zhang, et al. Hunyuanvideo: A systematic framework for large video generative models. arXiv preprint arXiv:2412.03603, 2024. <a href="https://arxiv.org/abs/2412.03603" target="_blank" style="color: #0066cc; text-decoration: none;">arXiv:2412.03603</a>.
          </p>
          <p style="margin-bottom: 1.25rem;">
            <strong>Opensora:</strong> Langwei Zheng, Xiangyu Peng, Tianji Yang, Chenhui Shen, Shenggui Li, Hongxin Liu, Yukun Zhou, Tianyi Li, and Yang You. Open-sora: Democratizing efficient video production for all. arXiv preprint arXiv:2412.20404, 2024. <a href="https://arxiv.org/abs/2412.20404" target="_blank" style="color: #0066cc; text-decoration: none;">arXiv:2412.20404</a>.
          </p>
          <p style="margin-bottom: 1.25rem;">
            <strong>VideoScore2:</strong> Lian Zheng, Ziqi Huang, Hongbo Liu, Kai Zou, Yinan He, Fan Zhang, Lulu Gu, Yuanhan Zhang, Jingwen He, Wei-Shi Zheng, et al. Vbench-2.0: Advancing video generation benchmark suite for intrinsic faithfulness. arXiv preprint arXiv:2503.21755, 2025. <a href="https://arxiv.org/abs/2503.21755" target="_blank" style="color: #0066cc; text-decoration: none;">arXiv:2503.21755</a>.
          </p>
          <p style="margin-bottom: 1.25rem;">
            <strong>VideoPhy-2:</strong> Ritik Bansal, Clark Peng, Yonatan Bitton, Roman Goldenberg, Aditya Grover, and Kai-Wei Chang. Videophy-2: A challenging action-centric physical commonsense evaluation in video generation. arXiv preprint arXiv:2503.06800, 2025. <a href="https://arxiv.org/abs/2503.06800" target="_blank" style="color: #0066cc; text-decoration: none;">arXiv:2503.06800</a>.
          </p>
          <p style="margin-bottom: 1.25rem;">
            <strong>GPT-5:</strong> OpenAI. Gpt-5 system card. Technical report, OpenAI, 2025. Accessed: 2025-11-10.
          </p>
          <p style="margin-bottom: 0;">
            <strong>Gemini-2.5-Pro:</strong> Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, et al. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261, 2025. <a href="https://arxiv.org/abs/2507.06261" target="_blank" style="color: #0066cc; text-decoration: none;">arXiv:2507.06261</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End References section -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
